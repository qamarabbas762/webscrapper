import asyncio
from playwright.async_api import async_playwright, Page
from typing import Any


async def scrape(page: Page, url: str) -> None:
    # Navigate to the specified URL
    await page.goto(url)

    # Select elements for links and text
    document_link_elements = await page.query_selector_all("//div[@class='text-row']//a[@class='btn-icon']")
    text_elements = await page.query_selector_all("//div[@class='text-row']//div[@class='text']")

    # Check if there's a mismatch in the number of elements
    if len(document_link_elements) != len(text_elements):
        print("Error: Mismatch in the number of link and text elements")
        return

    # Loop through both lists simultaneously
    for link_element, text_element in zip(document_link_elements, text_elements):
        # Get the href attribute for the link
        href = await link_element.get_attribute("href")
        if not href:
            print("Error: No href attribute found")
            continue

        # Get the text content for the heading
        name = await text_element.text_content()  # Use text_content() to extract text

        if name:
            # Save or process the data as needed
            print({"name": name.strip(), "url": href})  # Example output
        else:
            print("Error: No text content found")


async def main() -> None:
    async with async_playwright() as p:
        # Initialize Playwright components
        browser = await p.chromium.launch(headless=False)  # Set headless to True if needed
        context = await browser.new_context()
        page = await context.new_page()

        # Example URL to scrape
        url = "http://ida.gov.eg/webcenter/portal/IDA/pages_industrialbuildingprocesscopy"  # Change as needed

        # Call the scrape function with the page and URL
        await scrape(page, url)

        # Cleanup
        await browser.close()


# Run the asynchronous main function
asyncio.run(main())
